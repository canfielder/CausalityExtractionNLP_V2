---
title: "Entity Extraction Performance Evaluation - R & Python"
author: "Evan Canfield"
date: "12/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose
The purpose of this notebook is to test how to implement the Entity Extraction model 

# Import
## Libraries
```{r import_libraries}
  if (!require(pacman)) {install.packages('pacman')}
  p_load(
    dplyr,
    readxl,
    reticulate,
    rtika,
    stringr,
    tokenizers,
    tidyr
  )
```

## Source Files
The following imports functions defined in the sourced R scripts.
```{r}
# Import All Scripts
script_path <- "../R/"
file_paths <- list.files(recursive = TRUE, 
                         path = script_path, pattern = ".R", 
                         full.names = TRUE)

for (file in file_paths){
  source(file)
}
```

## Data
```{r import_data}
# PDF Input
## Define Path
pdf_path <- "./../data/acadmic_papers_pdf_sample/afglmm10hrm.pdf"

## Import and Convert to Text
pdf_txt_raw <- tika_text(pdf_path)

# Patterns File
patterns_col <- c("remove","comments")
patterns_raw <- read_excel(path = "./../data/patterns.xlsx", col_names = patterns_col, )
patterns <- patterns_raw %>% pull(remove)
```

# Process Data
## Process Text and Extract Hypotheses
```{r}
# Process Text
text_processed <- process_text(input_text = pdf_txt_raw, 
                                  removal_patterns = patterns)

input_text <- text_processed
```

```{r}
  # Concatenate All Vector Elements, Separated By Line Split
  processing_text <- str_c(input_text, collapse = " ")
  processing_text <- tokenize_sentences(processing_text,
                                        strip_punct = FALSE) %>% unlist()

  # Replace Double Spaces
  processing_text <- str_replace_all(string = processing_text,
                            pattern = "  ",
                            replacement = " ")

  # Normalize Text ------------------------------------------------------------
  processing_text <- tolower(processing_text)
```

```{r}
# Regex - Between Hypo and Colon
regex_hypo_marker <- "<split>hypo (.*?):"

# Hypothesis Extraction -----------------------------------------------------
  # Identify Lines with Hypothesis Pattern
  h_match <- processing_text %>% str_match(regex_hypo_marker)
  
  # Extract Hypotheses Number
  h_match_num <- h_match[,2]
  
  # Identify Unique Hypothesis Numbers
  h_match_num_unq <- unique(h_match_num)
  
  # Drop NA
  h_match_num_unq <- h_match_num_unq[!is.na(h_match_num_unq)]
  
  # Determine Vector Index of Initial Hypothesis Statements
  h_initial <- c()
  for (i in h_match_num_unq){
    intial_idx <- tapply(seq_along(h_match_num),
                         h_match_num,
                         min)[i]
    h_initial <- c(h_initial, intial_idx)
  }
  
  # Reduce Text to Only Initial Hypothesis Instances
  h_statements <- processing_text[h_initial]
  
  h_statements
```

```{r}
  # Split Statements On Indicator (Defined in Processing) ---------------------
  ## Define
  split_indicator <- "<split>"

  ## Split on Indicator
  h_statements <- str_split(string = h_statements,
                                     pattern = split_indicator) %>%
    unlist()

  ## Detect Statements Which Contain "Hypo"
  logical_hypothesis_2 <- str_detect(h_statements, "hypo")

  ## Drop Statements that Do Not Include "Hypo"
  h_statements <- h_statements[logical_hypothesis_2]
  
  h_statements

```

```{r}
  # Drop ~Hypo #:~
  h_statements <- gsub(".*: ","",h_statements)
  
  h_statements
```


```{r}
  # Create Dataframe with Hypothesis Number and Hypothesis
  df_hypothesis <- as.data.frame(h_statements,
                                 stringsAsFactors = FALSE)
```


```{r}
df_hypothesis
```


```{r}
gsub(".*: ","",h_statements)
```


```{r}


  # Identify Hypothesis Statements --------------------------------------------
  ## Return Logical Vector
  logical_hypothesis_1 <- str_detect(processing_text, regex_hypothesis)

  ## Reduce Document to Only Hypothesis Statements
  hypothesis_statements <- processing_text[logical_hypothesis_1]

  # Split Statements On Indicator (Defined in Processing) ---------------------
  ## Define
  split_indicator <- "<split>"

  ## Split on Indicator
  hypothesis_statements <- str_split(string = hypothesis_statements,
                                     pattern = split_indicator) %>%
    unlist()

  ## Detect Statements Which Contain "Hypo"
  logical_hypothesis_2 <- str_detect(hypothesis_statements, "hypo")

  ## Drop Statements that Do Not Include "Hypo"
  hypothesis_statements <- hypothesis_statements[logical_hypothesis_2]

  # Create Dataframe with Hypothesis Number and Hypothesis
  df_hypothesis <- as.data.frame(hypothesis_statements,
                                 stringsAsFactors = FALSE)


  # Rename and add Hypothesis Number
  df_hypothesis <- df_hypothesis %>%
    rename(hypothesis = hypothesis_statements) %>%
    mutate(
      h_id = paste0("h_", row_number())
    ) %>%
    select(h_id, hypothesis)
```

